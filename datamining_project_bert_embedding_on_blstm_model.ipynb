{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140cc272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertModel\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class Bertencoder(nn.Module):\n",
    "    def __init__(self, bert_dim, output_dim, num_layers, rnn_dim):\n",
    "        super(Bertencoder, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.rnn = nn.LSTM(bert_dim, rnn_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(rnn_dim*2, output_dim)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, y, seg_ids, mask):\n",
    "        bert_output = self.bert_model(x, token_type_ids=seg_ids, attention_mask=mask)\n",
    "        lstm_output, _ = self.rnn(bert_output.last_hidden_state)\n",
    "        output = self.linear(lstm_output).transpose(1, 2)\n",
    "        loss = self.loss_function(output, y)\n",
    "        return loss\n",
    "\n",
    "    def test(self, x, y, seg_ids, mask):\n",
    "        bert_output = self.bert_model(x, token_type_ids=seg_ids, attention_mask=mask)\n",
    "        lstm_output, _ = self.rnn(bert_output.last_hidden_state)\n",
    "        output = self.linear(lstm_output).transpose(1, 2)\n",
    "        loss = self.loss_function(output, y)\n",
    "        predict = self.predict_label(output.transpose(1, 2), mask)\n",
    "        return loss, predict\n",
    "\n",
    "    def predict(self, x, seg_ids, mask):\n",
    "        bert_output = self.bert_model(x, token_type_ids=seg_ids, attention_mask=mask)\n",
    "        lstm_output, _ = self.rnn(bert_output.last_hidden_state)\n",
    "        output = self.linear(lstm_output).transpose(1, 2)\n",
    "        return output.transpose(1, 2).argmax(2)\n",
    "\n",
    "    def predict_label(self, output, mask):\n",
    "        \"\"\"\n",
    "        output: batch_size, max_sentence_len, tag_num\n",
    "        mask: same label data\n",
    "        batch_label: batch_size, sentence_label\n",
    "        \"\"\"\n",
    "        pre_label = []\n",
    "        pre_label_pad = output.argmax(2)\n",
    "        for i in range(mask.shape[0]):\n",
    "            sent_label = []\n",
    "            for j in range(mask.shape[1]):\n",
    "                if mask[i, j] == 1:\n",
    "                    sent_label.append(pre_label_pad[i, j].item())\n",
    "            sent_label = sent_label[1:len(sent_label)-1]\n",
    "            pre_label.append(sent_label)\n",
    "\n",
    "        return pre_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a57538",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_labels = {',': 'I-COMMA',\n",
    "                  '.': 'I-DOT',\n",
    "                  '?': 'I-QMARK',\n",
    "                  '!': 'I-EMARK',\n",
    "                  ':': 'I-COLON',\n",
    "                  ';': 'I-SEMICOLON'}\n",
    "normal_label = 'O'\n",
    "labels_set = list(special_labels.values()) + [normal_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d90b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = NERArgs()\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.save_steps = -1\n",
    "ner_model = NERModel('bert',\n",
    "                 'bert-base-uncased',\n",
    "                 labels = labels_set,\n",
    "                 args=model_args,\n",
    "                 use_cuda=False)\n",
    "ner_model.args.max_seq_length = 512\n",
    "train_df = pd.read_csv('./wikitext/train0-10.csv').dropna()\n",
    "validation_df = pd.read_csv('./wikitext/validation.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23966ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ner_model.load_and_cache_examples(train_df[:])\n",
    "validation_dataset = ner_model.load_and_cache_examples(validation_df[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aea700",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe606750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm, trange\n",
    "from torch.optim import Adam, SGD\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "bert_dim = 768\n",
    "output_dim = len(labels_set)\n",
    "batch_size = 32\n",
    "adam_lr = 3e-5\n",
    "epoch = 1\n",
    "num_layers = 1\n",
    "rnn_dim = 512\n",
    "model = Bertencoder(bert_dim, output_dim, num_layers, rnn_dim)\n",
    "\n",
    "def train(model, tr_ds, val_ds):\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_gpu else 'cpu')\n",
    "    train_dataloader = DataLoader(tr_ds, batch_size=batch_size, shuffle=False)\n",
    "    validation_dataloader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    if use_gpu:\n",
    "        model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=adam_lr)\n",
    "    for i in range(epoch):\n",
    "        epoch_loss = 0\n",
    "        batch_iterator = tqdm(train_dataloader, desc=f\"Running Epoch {i+1} of {epoch}\", mininterval=0)\n",
    "        \n",
    "        for (j, batch) in enumerate(batch_iterator):\n",
    "            batch_x = batch[0].to(device)\n",
    "            batch_y = batch[3].to(device)\n",
    "            batch_seg = batch[2].to(device)\n",
    "            batch_msk = batch[1].to(device)\n",
    "            loss = model(batch_x, batch_y, batch_seg, batch_msk)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        dev_loss = 0\n",
    "        predict_idx_label = []\n",
    "\n",
    "        for (h, val_batch) in enumerate(validation_dataloader):\n",
    "            val_batch_x = val_batch[0].to(device)\n",
    "            val_batch_y = val_batch[3].to(device)\n",
    "            val_batch_seg = val_batch[2].to(device)\n",
    "            val_batch_msk = val_batch[1].to(device)\n",
    "            with torch.no_grad():\n",
    "                loss_val, pre_y = model.test(val_batch_x, val_batch_y, val_batch_seg, val_batch_msk)\n",
    "            dev_loss += loss_val.item()            \n",
    "            predict_idx_label.append(pre_y)\n",
    "        print(f\"Epoch {i+1}/{epoch}:\\n\\tTraining Loss: \\t\\t{epoch_loss/(j+1):9.4f}\\n\\tValidation Loss: \\t{dev_loss/(h+1):9.4f}\")\n",
    "        print('*******************************************************')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_dataset, validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52617d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff959b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24583b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303f175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f422d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa2cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53168d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from simpletransformers.ner.ner_utils import InputExample\n",
    "\n",
    "def test_model(to_predict, predictor_model, ner_model):\n",
    "    predict_examples = [InputExample(i,sentence.split(),[ner_model.args.labels_list[0] for word in sentence.lower().split()],) for i, sentence in enumerate(to_predict)]\n",
    "    eval_dataset = ner_model.load_and_cache_examples(None, evaluate=True, no_cache=True, to_predict=predict_examples)\n",
    "    eval_sampler = SequentialSampler(eval_dataset)\n",
    "    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=batch_size)\n",
    "    \n",
    "    eval_batch_iterator = tqdm(eval_dataloader, desc=f\"Testing!\", mininterval=0)\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    device = torch.device('cuda:0' if use_gpu else 'cpu')\n",
    "    for (j, val_batch) in enumerate(eval_batch_iterator):\n",
    "        val_batch_x = val_batch[0].to(device)\n",
    "        val_batch_y = val_batch[3].to(device)\n",
    "        val_batch_seg = val_batch[2].to(device)\n",
    "        val_batch_msk = val_batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            pre_y = predictor_model.predict(val_batch_x, val_batch_seg, val_batch_msk)\n",
    "        out_label_ids = [[] for _ in range(len(val_batch_x))]\n",
    "\n",
    "        max_len = np.max([len(x) for x in val_batch_x])\n",
    "        for index, sentence in enumerate(to_predict):\n",
    "            for word in sentence.split():\n",
    "                word_tokens = ner_model.tokenizer.tokenize(word)\n",
    "                out_label_ids[index].extend([0] + [-100] * (len(word_tokens) - 1))\n",
    "            out_label_ids[index].insert(0, -100)\n",
    "            out_label_ids[index].append(-100)\n",
    "            if len(out_label_ids[index]) < max_len:\n",
    "                out_label_ids[index].extend([-100] * (max_len - len(out_label_ids[index])))\n",
    "        xfer_label_ids = np.zeros((len(out_label_ids), max_len))\n",
    "        for i, out_label_id in enumerate(out_label_ids):\n",
    "            for j, label in enumerate(out_label_id):\n",
    "                xfer_label_ids[i][j] = np.int32(label)\n",
    "        out_label_ids = np.array([list(x) for x in out_label_ids], np.int32)\n",
    "        preds = pre_y.to(\"cpu\")\n",
    "        label_map = {i: label for i, label in enumerate(labels_set)}\n",
    "        out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        for i in range(out_label_ids.shape[0]):\n",
    "            for j in range(out_label_ids.shape[1]):\n",
    "                if out_label_ids[i, j] != -100:\n",
    "                    out_label_list[i].append(label_map[out_label_ids[i][j]])\n",
    "                    preds_list[i].append(label_map[preds[i][j].item()])\n",
    "    return preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = [\"First the reading points out that it is imperative for the employees to participate in meetings because meetings are effective for talking about controversial subjects\", \"This is in direct contrast with the statement of the listening which contends that meetings should be avoided\", \"He explains that in long meetings bosses spend time reciting introductory information Thus employees do not pay attention in a meeting exceeding an hour Therefore he suggests that the employees politely decline the meeting pointing at a pressing obligation that can be done through a quick phone call or email\", \"In addition the writer says that it employees should make effort to read all of the training and supplementary material\", \"When reading such articles the author explains that it is instrumental for the employees to pay attention to the details of the text However the professor refutes this argument claiming that employees should rather try to find the main idea rather than focusing on the intricate details since it takes up an unnecessary amount of time\", \"He goes as far to claim that employees should refuse to read the entire material even if their bosses request them to do so\",\n",
    "             \"Finally according to the reading employees should write their report in one attempt Since the employees are no longer in university they no longer have the luxury to waste time in separating the steps when writing This is challenged by the argument of the listening material that when one does not separate the steps in writing it can be more tire time consuming Thus the professor recommends that the employees write divide the writing into three distinct steps creating an outline writing a first draft and revising the essay In this way the professor ascertains that employees will be able to complete their writing in a timely and accurate manner Finally according to the reading employees should write their report in one attempt Since the employees are no longer in university they no longer have the luxury to waste time in separating the steps when writing This is challenged by the argument of the listening material that when one does not separate the steps in writing it can be more tire time consuming Thus the professor recommends that the employees write divide the writing into three distinct steps creating an outline writing a first draft and revising the essay In this way the professor ascertains that employees will be able to complete their writing in a timely and accurate manner\"]\n",
    "out_labels = test_model(to_predict=to_predict, predictor_model=model, ner_model=ner_model)\n",
    "\n",
    "for i, sent in enumerate(to_predict):\n",
    "    print(len(sent.split()))\n",
    "    print(len(out_labels[i]))\n",
    "print(out_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444abbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243f0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d54104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b84969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c689c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa88467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./bert_on_blstm_models/0/model.json\")\n",
    "model = Bertencoder(bert_dim, output_dim, num_layers, rnn_dim)\n",
    "model.load_state_dict(torch.load(\"./bert_on_blstm_models/0/model.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cf058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
